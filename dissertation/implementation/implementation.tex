% !TEX root = ../main.tex

\chapter{Implementation}

\section{Technology Used}

There are various technologies used within this project. These are Python 3.9, Visual Studio Code, Git, AntConc 3.5.9, Rocksteady 0.4 and Gretl. Each of these had a different function within the project.

\subsection{Python 3.9}

Python is an interpreted, high-level and general-purpose programming language. The version used was version 3.9. 

Python was used in this project to develop and execute the procedures outlined in the implementation. This is due to the fact that python is a very useful language for handling projects which require a large amount of various different features as it is general purpose. For that reasons it has many publicly available libraries which help for many of the scenarios come across throughout development.

The libraries used had three main purposes: file handling, data tidying and mathematical operations.

\subsubsection{File Handling}

In order to handle the files downloaded from *lexisnexis* and *proquest*, various libraries and modules had to be used. The libraries and modules being `sys`, `os` and `striprtf`.

The `sys` module provides functions and variables used to manipulate different parts of the Python runtime environment. It is used to create a global variable which allowed the setting of a source for files, and allowed this to be used throughout the various files in the program. The source being the choice between using *lexisnexis* and *proquest* files.

The `os` module provides functions and variables used to perform operating system tasks. It is used to access environment variables, as well as to help parse through files in a given directory.

The `striprtf` library is used to translate rtf to a python string. When files are downloaded from *lexinexis* they are in rtf format, This library is used to help parsed the informaiton in these files into a usable format.

\subsubsection{Data Tidying}

In order to tidy up the data extracted from articles and make it usable in the context required the use of some libraries is needed. These libraries and modules are `pandas`, `json`, `copy`, `datetime` and `operator`.

The `pandas` is an open source data analysis and manipulation tool. This library is used to aid in the tabling of data. This was useful in order to use this data within graphs and to create an excel spreadsheet. For graphing timeseries, this library was especially useful with it's `to_datetime()` function which allowed the dates to be appropriately used as indices. This is significant especially when comparing two separate time series, as it spaced the values according to date and not which datapoint it is along the sequence.

The `json` library is used to dump json data from files and the extract it back from the file in order to cache the information extracted for future use.

The `copy` library is used to create deepcopies of json objects. This is necessary as the copies had to be completely separate from the original version, and due to how python works this cannot simply be done through a shallow copy. Therefore the library was used to facilitate this.

The `datetime` module supplies classes for manipulating dates and times. As they are usually stored in strings they can be complex to perform operations with. The library makes this process a lot more straightforward.

The `operator` module exports a set of efficient functions corresponding to the intrinsic operators of Python. It is used sort arrays of json objects that contain a given key. This was very useful when ordering data entries by date.

\subsubsection{Mathematical Operations}

In order to perform mathematical operations appropriately multiple libraries are used. This is to avoid the recreation of tested and efficient functions, and avoid any potential errors when recreating them. These libraries and modules are `numpy`, `statistics`, `scipy`, `math` and `sklearn`.

The `numpy` is a Python library used for working with arrays. It also has functions for working in domain of linear algebra, fourier transform, and matrices.

The `statistics` is a built-in Python library for descriptive statistics.

The `scipy` is a collection of mathematical algorithms and convenience functions built on the `numpy` extension of Python. It adds significant power to the interactive Python session by providing the user with high-level commands and classes for manipulating and visualizing data. Specifically the `scipy.stats` module was used. Similarly, to the `statistics` library it was used to gather various types of statistical information.

The `math` module is a built-in module that you can use for mathematical tasks. It is used specifically for the `log()` function contained within.

The `sklearn` library is an incredibly useful machine learning library. The `sklearn` library contains a lot of efficient tools for machine learning and statistical modeling including classification, regression, clustering and dimensionality reduction. It is used for the machine learning functionality required for the `singlePointEstimator`. These being various trainable models, appropriately metric measuring functions, and some utility functions.

\subsection{Visual Studio Code}

TODO What?
TODO Why?
TODO How?

\subsection{Git}

TODO What?
TODO Why?
TODO How?

\subsection{AntConc 3.5.9}

TODO What?
TODO Why?
TODO How?

\subsection{Rocksteady 0.4}

TODO What?
TODO Why?
TODO How?

\subsection{Gretl}

TODO What?
TODO Why?
TODO How?

\section{Setting up the System}
TODO
\subsection{more subsections}
TODO
\section{User Interfaces}
TODO
\subsection{more subsections}
TODO
\section{Implementation Summary}
TODO